experiment_name: "BASELINE-ZERO-ACTION"
environment:
  class_path: CR_LoFi.atcenv.src.environment_objects.environment.DefaultEnvironment
  init_args:
    render_frequency: 0
model: {}
scenario:
  num_episodes: 1000
  num_agents: 1
  num_flights: 0
  num_ac_state: 4
  airspace_area: [2400, 3750]
  traffic_density: [0.005, 0.001]
  test_scenario_dir: "hello"
  num_test_episodes: 0
  test_frequency: 0
  random_seed: 42
airspace:
  class_path: CR_LoFi.atcenv.src.environment_objects.airspace.EnrouteAirspace
aircraft:
  min_speed: 250
  max_speed: 250
  min_distance: 9260
observation:
  class_path: CR_LoFi.atcenv.src.observation.observation.Local
  init_args:
    observation_size: 31
    num_ac_state: 4
    normalize_data: True
    create_normalization_data: False
    normalization_data_file: "local_normalization.p"
    normalization_samples: 1000
reward:
  class_path: CR_LoFi.atcenv.src.reward.reward.DefaultReward
  init_args:
    intrusion_weight: -1
    drift_weight: -0.1
logger:
  class_path: CR_LoFi.atcenv.src.logger.logger.RLLogger
  init_args:
    log_frequency: 25
    verbose: True
baseline: True